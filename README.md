# SignTalk

**SignTalk** is an AI-powered real-time video conferencing application that aims to bridge the communication gap between spoken language and sign language. It provides real-time speech-to-text and sign-language-to-text translation using custom AI models. This is currently an MVP focused on real-time communication infrastructure.

## ğŸš€ Features

- ğŸ”Š **Speech-to-Text AI Model** *(WIP)*  
  Automatically transcribes spoken audio from video calls into readable text.

- ğŸ§â€â™‚ï¸ **Sign Language to Text AI Model** *(WIP)*  
  Detects sign language from video frames and translates it into written text.

- ğŸ“¹ **Real-Time Video Conferencing**  
  Built with custom WebRTC and WebSocket implementationâ€”no third-party video APIs.

- ğŸŒ **Full Stack Integration**  
  Developed using a modern web stack for scalability and speed.

---

## ğŸ›  Tech Stack

### Frontend
- [Next.js](https://nextjs.org/) (React Framework)
- TypeScript

### Backend
- Python (for AI and backend logic)
- Supabase (authentication and database)
- Custom WebRTC & WebSocket implementation

### Machine Learning (Planned Integration)
- ğŸ§  **AI Speech Model** â€” For live speech-to-text transcription
- âœ‹ **AI Sign Language Model** â€” For video sign language recognition

---

## âš™ï¸ Implementation Details

- âœ… Custom-built **WebRTC** signaling and **WebSocket** communication with no reliance on third-party APIs.
- ğŸ§ª Currently in **MVP stage**:  
  - WebRTC and WebSocket fully functional  
  - AI integration (speech and sign language models) is not yet implemented  
- ğŸ§± Modular architecture designed to integrate AI models smoothly in future iterations.

---

## ğŸ“Œ Roadmap

- [x] Real-time video communication with WebRTC
- [x] Real-time signaling and messaging with WebSocket
- [ ] Integrate AI speech recognition model
- [ ] Integrate AI sign language recognition model
- [ ] Add user interface improvements
- [ ] Deploy to production

---

## ğŸ“‚ Project Structure (High-Level)

