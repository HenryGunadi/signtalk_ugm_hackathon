{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dfd171f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 20:40:33.774463: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# === Config ===\n",
    "SEQUENCE_LENGTH = 15\n",
    "IMG_SIZE = 224\n",
    "CONFIDENCE_THRESHOLD = 0.8\n",
    "COOLDOWN_SECONDS = 2.0  # Cooldown between valid predictions\n",
    "CLASSES = ['bed', 'before', 'candy', 'cool', 'drink', 'go', 'help', 'thin']\n",
    "\n",
    "# --- Load Model ---\n",
    "model = load_model('asl_mobilenetv2_finetuned.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec552ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 20:40:52.322 Python[11422:575160] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "2025-04-08 20:40:54.171 Python[11422:575160] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:41:02] Prediction: before (91.3%)\n",
      "[20:41:04] Prediction: before (92.8%)\n",
      "[20:41:06] Prediction: before (90.0%)\n",
      "[20:41:08] Prediction: before (88.9%)\n",
      "[20:41:12] Prediction: before (83.5%)\n",
      "[20:41:14] Prediction: before (86.9%)\n",
      "[20:41:18] Prediction: before (82.2%)\n",
      "[20:41:23] Prediction: before (82.7%)\n",
      "[20:41:26] Prediction: before (88.4%)\n",
      "[20:41:29] Prediction: before (94.5%)\n",
      "[20:41:32] Prediction: before (86.3%)\n",
      "[20:41:38] Prediction: drink (83.6%)\n",
      "[20:41:40] Prediction: thin (93.8%)\n",
      "[20:41:43] Prediction: drink (80.9%)\n",
      "[20:41:45] Prediction: thin (82.8%)\n",
      "[20:41:47] Prediction: drink (93.2%)\n",
      "[20:41:49] Prediction: drink (95.0%)\n",
      "[20:41:51] Prediction: go (83.3%)\n",
      "[20:41:53] Prediction: go (91.5%)\n",
      "[20:41:55] Prediction: thin (83.1%)\n",
      "[20:42:00] Prediction: help (86.4%)\n",
      "[20:42:03] Prediction: help (81.8%)\n",
      "[20:42:07] Prediction: help (85.4%)\n",
      "[20:42:09] Prediction: thin (90.2%)\n",
      "[20:42:16] Prediction: bed (95.6%)\n",
      "[20:42:18] Prediction: thin (81.6%)\n",
      "[20:42:21] Prediction: bed (99.9%)\n",
      "[20:42:23] Prediction: bed (99.9%)\n",
      "[20:42:29] Prediction: thin (81.5%)\n",
      "[20:42:32] Prediction: drink (88.2%)\n",
      "[20:42:35] Prediction: thin (81.3%)\n",
      "[20:42:39] Prediction: before (91.0%)\n",
      "[20:42:46] Prediction: drink (83.5%)\n",
      "[20:42:48] Prediction: thin (92.2%)\n",
      "[20:42:52] Prediction: thin (87.0%)\n",
      "[20:42:54] Prediction: thin (86.8%)\n",
      "[20:43:00] Prediction: drink (90.8%)\n",
      "[20:43:02] Prediction: drink (86.6%)\n",
      "[20:43:04] Prediction: thin (82.3%)\n",
      "[20:43:06] Prediction: bed (87.0%)\n",
      "[20:43:13] Prediction: thin (86.8%)\n",
      "[20:43:18] Prediction: thin (80.5%)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# === Init webcam and sequence queue ===\n",
    "cap = cv2.VideoCapture(0)\n",
    "sequence = deque(maxlen=SEQUENCE_LENGTH)\n",
    "label = \"\"\n",
    "confidence = 0.0\n",
    "last_prediction_time = 0\n",
    "\n",
    "# === Prediction log list ===\n",
    "prediction_log = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    resized_frame = cv2.resize(frame, (IMG_SIZE, IMG_SIZE))\n",
    "    normalized_frame = resized_frame.astype(\"float32\") / 255.0\n",
    "\n",
    "    sequence.append(normalized_frame)\n",
    "\n",
    "    # Predict only if sequence is full AND cooldown passed\n",
    "    current_time = time.time()\n",
    "    if len(sequence) == SEQUENCE_LENGTH and (current_time - last_prediction_time > COOLDOWN_SECONDS):\n",
    "        input_data = np.expand_dims(sequence[-1], axis=0)  # Shape: (1, 15, 224, 224, 3)\n",
    "        prediction = model.predict(input_data, verbose=0)[0]\n",
    "        confidence = np.max(prediction)\n",
    "        predicted_index = np.argmax(prediction)\n",
    "\n",
    "        if confidence > CONFIDENCE_THRESHOLD:\n",
    "            label = f\"{CLASSES[predicted_index]} ({confidence*100:.1f}%)\"\n",
    "            last_prediction_time = current_time\n",
    "\n",
    "            # Print to notebook\n",
    "            print(f\"[{time.strftime('%H:%M:%S')}] Prediction: {CLASSES[predicted_index]} ({confidence*100:.1f}%)\")\n",
    "            prediction_log.append((time.strftime('%H:%M:%S'), CLASSES[predicted_index], confidence))\n",
    "\n",
    "    # === Subtitle display ===\n",
    "    height, width, _ = frame.shape\n",
    "    if label:\n",
    "        cv2.rectangle(frame, (0, height - 40), (width, height), (0, 0, 0), -1)\n",
    "        cv2.putText(frame, label, (10, height - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"ASL Real-Time Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
